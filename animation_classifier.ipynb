{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "Classify the user-provided image into one of these categories: \n",
    "* anime\n",
    "* Disney animation\n",
    "* soviet animation\n",
    "    \n",
    "The code is based on the code from this repo: https://github.com/fastai/fastbook , which was released under a free licence (GPL-3). The code changes include: making the code work for any classes, refactoring.\n",
    "\n",
    "The final model is based on a pre-trained [resnet18](https://pytorch.org/hub/pytorch_vision_resnet/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT THE LINES BELOW IF YOU WANT TO TRAIN YOUR OWN CLASSIFIER\n",
    "# !pip install -Uqq fastbook\n",
    "# import fastbook\n",
    "# fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastbook import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credentials\n",
    "Replace the *secret_key_dont_share_it* below with your own key. For how to get the key, see [this](https://forums.fast.ai/t/getting-the-bing-image-search-key/67417)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_key_dont_share_it = 'REPLACE WITH YOURS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n",
    "If you want to create another image classifier, replace the classes names below with your own. The names are also the terms that Bing will search to build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_names = 'anime','disney animation','soviet animation'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_from_bing_images(categories):\n",
    "    key = os.environ.get('AZURE_SEARCH_KEY', secret_key_dont_share_it)\n",
    "    dir_name = \"_\".join(categories).replace(\" \", \"_\")\n",
    "    path = Path(dir_name)\n",
    "    \n",
    "    if not path.exists():\n",
    "        path.mkdir()\n",
    "        for o in categories:\n",
    "            dest = (path/o)\n",
    "            dest.mkdir(exist_ok=True)\n",
    "            results = search_images_bing(key, o)\n",
    "            download_images(dest, urls=results.attrgot('content_url'))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_failed_downloads(path):\n",
    "    fns = get_image_files(path)\n",
    "    failed = verify_images(fns)\n",
    "    display(print(\"There are this many failed dowloads to delete:\", len(failed)))\n",
    "    failed.map(Path.unlink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloaders(path):\n",
    "    raw_elements = DataBlock(\n",
    "        blocks=(ImageBlock, CategoryBlock), \n",
    "        get_items=get_image_files, \n",
    "        splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "        get_y=parent_label,\n",
    "        item_tfms=Resize(128))\n",
    "    raw_dls = raw_elements.dataloaders(path)\n",
    "    return raw_dls, raw_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_and_augment(elements, path):\n",
    "    elements = elements.new(\n",
    "        item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
    "        batch_tfms=aug_transforms())\n",
    "    dls = elements.dataloaders(path)\n",
    "    return dls, elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataset_sample(raw_dls, dls):\n",
    "    # \"Before and after augmentation:\"\n",
    "    raw_dls.train.show_batch(max_n=38, nrows=4)\n",
    "    dls.train.show_batch(max_n=38, nrows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(classes_names):\n",
    "    path = build_dataset_from_bing_images(classes_names)\n",
    "    remove_failed_downloads(path)\n",
    "    raw_dls, raw_elements = build_dataloaders(path)\n",
    "    dls, elements = resize_and_and_augment(raw_elements, path)\n",
    "    show_dataset_sample(raw_dls, dls)\n",
    "    return dls, elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_my_model(dls):\n",
    "    learn = cnn_learner(dls, resnet18, metrics=error_rate)\n",
    "    learn.fine_tune(10)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_training_results_diagrams(learn):\n",
    "    interp = ClassificationInterpretation.from_learner(learn)\n",
    "    interp.plot_confusion_matrix()  \n",
    "    interp.plot_top_losses(5, nrows=5)\n",
    "    cleaner = ImageClassifierCleaner(learn)\n",
    "    cleaner\n",
    "    # cleaner can be used to clean the dataset from the junk you marked:\n",
    "    # for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n",
    "    # for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(learn):\n",
    "    learn.export()\n",
    "    path = Path()\n",
    "    print(\"The model is saved to this file:\", path.ls(file_exts='.pkl'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_model():\n",
    "    dls, elements = get_dataset(classes_names)\n",
    "    learn = train_my_model(dls)\n",
    "    export_model(learn)\n",
    "    show_training_results_diagrams(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncomment this line to re-create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_new_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voila Online Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inference_learner():\n",
    "    path = Path()\n",
    "    learn_inf = load_learner(path/'export.pkl', cpu=True)\n",
    "    vocab = learn_inf.dls.vocab\n",
    "    return learn_inf, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_widgets():\n",
    "    btn_upload = widgets.FileUpload()\n",
    "    out_pl = widgets.Output()\n",
    "    out_pl.clear_output()\n",
    "    lbl_pred = widgets.Label()\n",
    "    btn_run = widgets.Button(description='Classify')\n",
    "    return btn_upload, btn_run, out_pl, lbl_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload, btn_run, out_pl, lbl_pred = build_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf, vocab = load_inference_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    img = PILImage.create(btn_upload.data[-1])\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(img.to_thumb(128,128))\n",
    "    pred,pred_idx,probs = learn_inf.predict(img)\n",
    "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_run.on_click(on_click_classify)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VBox([widgets.Label('I will try to classify your image as one of the following classes:' + str(vocab)), \n",
    "      btn_upload, btn_run, out_pl, lbl_pred])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
